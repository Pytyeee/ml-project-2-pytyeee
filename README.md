# PYTyeee-RoadSegmentation
CS-433 ML Project II


## Introduction
This project aims to identify roads in a set of aerial images from Google Maps. The task boils down to a binary classification of image regions into background or road labels, which can be done by training convolutional neural network (CNN) based models to classify each pixel or patch of the input images. The UNet architecture particularly caught our attention. The original dataset was augmented because of its limited size and in order to increase the model's performance. The best F1 score achieved on AIcrowd is 0.887.


## Requirements
To run the project, the following librairies/packages are required:
- Python
- Numpy
- Torch
- Matplotlib
- PIL
- Datetime
- Imgaug
- Segmentation_models_pytorch

They can be installed with `pip install -r requirements.txt`
 

## Project Structure
Our project repository is organized as follows : 
```
.
├── dataset                             # Original dataset
│   ├── test_set_images                     # Testing images (without groundtruth)
|   └── training                            # Training dataset (with groundtruth)
│       ├── augmented_groundtruth               # Groundtruth of the augmented images
│       ├── augmented_images                    # Augmented images
│       ├── groundtruth                         # Groundtruth initial not modified
│       └── images                              # Images initial not modified
├── model_saves                          # Model generated by training
├── notebooks                            # Notebook for training and augmentation
│   └── collab_unet.ipynb                    # Run the augmentation and the unet model on the dataset
├── submissions                          # Contains the best submission on AICrowd
├── data_augmentaion.py                  # Functions to augment the dataset
├── helpers_saving.py                    # Functions to save the model and the predection
├── preprocessing.py                     # Functions to load the images
└── README.md                         

```

## Run the project 
We run our model by using the free GPU available on Google Colab. The notebook collab_unet.ipynb can be imported on Google Collab and runned. It imports our GitHub repository. 


## Results:

