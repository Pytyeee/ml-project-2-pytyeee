{"cells":[{"cell_type":"code","execution_count":69,"metadata":{"id":"62osJXEdlbyZ","executionInfo":{"status":"ok","timestamp":1701180453570,"user_tz":-60,"elapsed":539,"user":{"displayName":"Ayskin","userId":"01523817379801193652"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6e82377e-b057-4771-cba7-daa24c95a2bc"},"outputs":[{"output_type":"stream","name":"stdout","text":["['/content', '/env/python', '/usr/lib/python310.zip', '/usr/lib/python3.10', '/usr/lib/python3.10/lib-dynload', '', '/usr/local/lib/python3.10/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.10/dist-packages/IPython/extensions', '/root/.ipython', '/content/ml-project-2-pytyeee/', '/content/ml-project-2-pytyeee/', '/content/ml-project-2-pytyeee/', '/content/ml-project-2-pytyeee/', '/content/ml-project-2-pytyeee/', '/content/ml-project-2-pytyeee', '/content/ml-project-2-pytyeee']\n"]}],"source":["import sys\n","import os\n","sys.path.append(\"/content/ml-project-2-pytyeee\")\n","\n","REPO_DIR = \"ml-project-2-pytyeee/\"\n","print(sys.path)"]},{"cell_type":"code","execution_count":70,"metadata":{"id":"ihvxa2zalbye","executionInfo":{"status":"ok","timestamp":1701180454571,"user_tz":-60,"elapsed":6,"user":{"displayName":"Ayskin","userId":"01523817379801193652"}}},"outputs":[],"source":["import segmentation_models_pytorch as smp\n","from scripts.preprocessing import *\n","from torch.utils.data import DataLoader, TensorDataset\n","import torch"]},{"cell_type":"code","execution_count":80,"metadata":{"id":"uAUO-vSvlbyf","executionInfo":{"status":"ok","timestamp":1701180496243,"user_tz":-60,"elapsed":786,"user":{"displayName":"Ayskin","userId":"01523817379801193652"}}},"outputs":[],"source":["NUM_CPU = 2 # os.cpu_count()\n","DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","TRAINING_SIZE = 100\n","BATCH_SIZE = 32\n","NUM_EPOCHS = 10\n","BASE_LR = 0.001\n","\n","ENCODER = 'resnet34'\n","ENCODER_WEIGHTS = 'imagenet'\n","ACTIVATION = 'sigmoid'"]},{"cell_type":"code","execution_count":72,"metadata":{"id":"BX-zlRVElbyh","outputId":"d85f7fda-8370-4943-9bda-84f13b446d37","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701180457633,"user_tz":-60,"elapsed":1682,"user":{"displayName":"Ayskin","userId":"01523817379801193652"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading ml-project-2-pytyeee/dataset/training/images/satImage_001.png\n","Loading ml-project-2-pytyeee/dataset/training/images/satImage_100.png\n","Loading ml-project-2-pytyeee/dataset/training/groundtruth/satImage_001.png\n","Loading ml-project-2-pytyeee/dataset/training/groundtruth/satImage_100.png\n","Input shapes: ((100, 400, 400, 3), (100, 400, 400))\n"]}],"source":["train_dir = REPO_DIR + \"dataset/training/\"\n","train_images_filename = train_dir + \"images/\"\n","train_masks_filename = train_dir + \"groundtruth/\"\n","\n","train_images = extract_data(train_images_filename, TRAINING_SIZE)\n","train_masks = extract_data(train_masks_filename, TRAINING_SIZE)\n","print(f\"Input shapes: {train_images.shape, train_masks.shape}\")"]},{"cell_type":"code","execution_count":73,"metadata":{"id":"gX3i6z6xlbyj","outputId":"1372edee-be6b-4905-cafa-0bc32c72534a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701180457636,"user_tz":-60,"elapsed":28,"user":{"displayName":"Ayskin","userId":"01523817379801193652"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["New shapes: (torch.Size([100, 3, 416, 416]), torch.Size([100, 1, 416, 416]))\n"]}],"source":["# Resize images to a size divisible by 32 to make it UNet compatible\n","train_data = img_resize(np.transpose(train_images, (0, 3, 1, 2)), (416, 416))\n","train_labels = img_resize(np.transpose(np.expand_dims(train_masks, -1), (0, 3, 1, 2)),  (416, 416))\n","\n","# 1 hot encode each non black pixel to 1 pixel\n","train_labels[train_labels > 0] = 1\n","print(f\"New shapes: {train_data.shape, train_labels.shape}\")"]},{"cell_type":"code","execution_count":74,"metadata":{"id":"d49Q7LKSlbyk","executionInfo":{"status":"ok","timestamp":1701180458985,"user_tz":-60,"elapsed":1363,"user":{"displayName":"Ayskin","userId":"01523817379801193652"}}},"outputs":[],"source":["# Create segmentation model with pretrained encoder\n","model = smp.Unet(\n","    encoder_name=ENCODER,\n","    encoder_weights=ENCODER_WEIGHTS,\n","    classes=1, # 1 for grayscale\n","    activation=ACTIVATION,\n",")\n","\n","model = model.to(DEVICE)\n","# preprocessing_fn = smp.encoders.get_preprocessing_fn(ENCODER, ENCODER_WEIGHTS)"]},{"cell_type":"code","execution_count":81,"metadata":{"id":"8Y-eYgSFlbyl","executionInfo":{"status":"ok","timestamp":1701180509320,"user_tz":-60,"elapsed":17,"user":{"displayName":"Ayskin","userId":"01523817379801193652"}}},"outputs":[],"source":["# Create dataset\n","road_dataset = TensorDataset(train_data, train_labels)\n","\n","# Get train and val data loaders\n","train_loader = DataLoader(road_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_CPU)"]},{"cell_type":"code","execution_count":76,"metadata":{"id":"Rq1PWQHQlbym","executionInfo":{"status":"ok","timestamp":1701180458986,"user_tz":-60,"elapsed":8,"user":{"displayName":"Ayskin","userId":"01523817379801193652"}}},"outputs":[],"source":["# define loss\n","criterion = smp.losses.DiceLoss('binary')\n","\n","# define optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr=BASE_LR)\n","\n","# define learning rate scheduler (not used in this NB)\n","lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n","    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",")"]},{"cell_type":"code","execution_count":77,"metadata":{"id":"OUJn-ZAslbym","executionInfo":{"status":"ok","timestamp":1701180458987,"user_tz":-60,"elapsed":7,"user":{"displayName":"Ayskin","userId":"01523817379801193652"}}},"outputs":[],"source":["def train_epoch(model, optimizer, scheduler, criterion, train_loader, epoch, device):\n","    # ***************************************************\n","    # Set model to training mode (affects dropout, batch norm e.g.)\n","    model.train()\n","\n","    loss_history = []\n","    accuracy_history = []\n","    f1_history = []\n","    lr_history = []\n","\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        # Move the data to the device\n","        data, target = data.to(device), target.to(device)\n","        # Zero the gradients\n","        optimizer.zero_grad()\n","        # Compute model output\n","        output = model(data)\n","        output = torch.where(output > 0.5, 1., 0.).requires_grad_()\n","        # Compute loss\n","        loss = criterion(output, target)\n","        # Backpropagate loss\n","        loss.backward()\n","        # Perform an optimizer step\n","        optimizer.step()\n","        # Perform a learning rate scheduler step\n","        scheduler.step()\n","        # Compute accuracy_float (float value, not a tensor)\n","        accuracy_float = torch.sum((output==target)) / torch.numel(target)\n","        # Compute loss_float (float value, not a tensor)\n","        loss_float = loss.item()\n","        # Add loss_float to loss_history\n","        loss_history.append(loss_float)\n","        # Add accuracy_float to accuracy_history\n","        accuracy_history.append(accuracy_float)\n","        # # Add learning rate to lr_history\n","        # lr_history.append(scheduler.get_last_lr()[0])\n","\n","        print(\n","            f\"Train Epoch: {epoch}-{batch_idx:03d} \"\n","            f\"batch_loss={loss_float:0.2e} \"\n","            f\"batch_acc={accuracy_float:0.3f} \"\n","            # f\"lr={scheduler.get_last_lr()[0]:0.3e} \"\n","        )\n","\n","    return loss_history, accuracy_history, lr_history, output, target"]},{"cell_type":"code","execution_count":82,"metadata":{"id":"mQMW7GV-lbyo","outputId":"49658ebb-1339-44d3-d24c-7db380e6c0ae","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701180528831,"user_tz":-60,"elapsed":15483,"user":{"displayName":"Ayskin","userId":"01523817379801193652"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1-000 batch_loss=6.41e-01 batch_acc=0.442 \n","Train Epoch: 1-001 batch_loss=6.23e-01 batch_acc=0.447 \n","Train Epoch: 1-002 batch_loss=6.55e-01 batch_acc=0.437 \n","Train Epoch: 1-003 batch_loss=6.33e-01 batch_acc=0.439 \n","Train Epoch: 2-000 batch_loss=6.57e-01 batch_acc=0.437 \n","Train Epoch: 2-001 batch_loss=6.42e-01 batch_acc=0.437 \n","Train Epoch: 2-002 batch_loss=6.20e-01 batch_acc=0.450 \n","Train Epoch: 2-003 batch_loss=6.42e-01 batch_acc=0.443 \n","Train Epoch: 3-000 batch_loss=6.30e-01 batch_acc=0.445 \n","Train Epoch: 3-001 batch_loss=6.36e-01 batch_acc=0.441 \n","Train Epoch: 3-002 batch_loss=6.58e-01 batch_acc=0.429 \n","Train Epoch: 3-003 batch_loss=6.14e-01 batch_acc=0.443 \n","Train Epoch: 4-000 batch_loss=6.34e-01 batch_acc=0.444 \n","Train Epoch: 4-001 batch_loss=6.48e-01 batch_acc=0.436 \n","Train Epoch: 4-002 batch_loss=6.31e-01 batch_acc=0.445 \n","Train Epoch: 4-003 batch_loss=6.88e-01 batch_acc=0.416 \n","Train Epoch: 5-000 batch_loss=6.27e-01 batch_acc=0.446 \n","Train Epoch: 5-001 batch_loss=6.46e-01 batch_acc=0.439 \n","Train Epoch: 5-002 batch_loss=6.46e-01 batch_acc=0.434 \n","Train Epoch: 5-003 batch_loss=6.36e-01 batch_acc=0.451 \n","Train Epoch: 6-000 batch_loss=6.43e-01 batch_acc=0.437 \n","Train Epoch: 6-001 batch_loss=6.47e-01 batch_acc=0.438 \n","Train Epoch: 6-002 batch_loss=6.34e-01 batch_acc=0.445 \n","Train Epoch: 6-003 batch_loss=5.99e-01 batch_acc=0.465 \n","Train Epoch: 7-000 batch_loss=6.48e-01 batch_acc=0.435 \n","Train Epoch: 7-001 batch_loss=6.45e-01 batch_acc=0.440 \n","Train Epoch: 7-002 batch_loss=6.32e-01 batch_acc=0.442 \n","Train Epoch: 7-003 batch_loss=5.98e-01 batch_acc=0.461 \n","Train Epoch: 8-000 batch_loss=6.34e-01 batch_acc=0.445 \n","Train Epoch: 8-001 batch_loss=6.39e-01 batch_acc=0.439 \n","Train Epoch: 8-002 batch_loss=6.45e-01 batch_acc=0.438 \n","Train Epoch: 8-003 batch_loss=6.47e-01 batch_acc=0.439 \n","Train Epoch: 9-000 batch_loss=6.34e-01 batch_acc=0.446 \n","Train Epoch: 9-001 batch_loss=6.57e-01 batch_acc=0.438 \n","Train Epoch: 9-002 batch_loss=6.34e-01 batch_acc=0.438 \n","Train Epoch: 9-003 batch_loss=5.86e-01 batch_acc=0.463 \n","Train Epoch: 10-000 batch_loss=6.27e-01 batch_acc=0.445 \n","Train Epoch: 10-001 batch_loss=6.27e-01 batch_acc=0.446 \n","Train Epoch: 10-002 batch_loss=6.58e-01 batch_acc=0.433 \n","Train Epoch: 10-003 batch_loss=6.98e-01 batch_acc=0.429 \n"]}],"source":["lr_history = []\n","train_loss_history = []\n","train_acc_history = []\n","val_loss_history = []\n","val_acc_history = []\n","for epoch in range(1, NUM_EPOCHS + 1):\n","    train_loss, train_acc, lrs, output, target = train_epoch(\n","        model, optimizer, lr_scheduler, criterion, train_loader, epoch, DEVICE\n","    )\n","    train_loss_history.extend(train_loss)\n","    train_acc_history.extend(train_acc)\n","    lr_history.extend(lrs)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"97cc609b13305c559618ec78a438abc56230b9381f827f22d070313b9a1f3777"}},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}